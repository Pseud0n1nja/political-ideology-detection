{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook that cleans up the raw debates json, arranges the debate transcripts, identifies speakers and removes HTML. This notebook covers a part of the debates (92 out of 148) which have clear indications of the participants in the debate transcripts. The other debates are in part 2 where the speakers have to be identified manually. \n",
    "\n",
    "**TO DO**: \n",
    "\n",
    "Break each statement down to sentences and make tabular csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"full_debates_raw.json\", \"r\") as f:\n",
    "    debates = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html(text):\n",
    "    \"\"\"\n",
    "    Clean up given string by removing all HTML tags and leaving only plain text\n",
    "    \"\"\"\n",
    "    pattern = re.compile(r\"<[^<]+?>\")\n",
    "    text_clean = re.sub(pattern, \"\", text)\n",
    "    return text_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speaker_list(debate_text):\n",
    "    \"\"\"\n",
    "    Function to obtain list of candidates and moderators for a given debate text\n",
    "    \"\"\"\n",
    "    debate_text_split = debate_text.split(\"<b>\")[1:]\n",
    "    speaker_text = []\n",
    "    for x in debate_text_split:\n",
    "        line_split = x.split(\":</b>\")\n",
    "        speaker_text.append(line_split)\n",
    "    candidates_desc = speaker_text[0][1]\n",
    "    moderators_desc = speaker_text[1][1]\n",
    "    speaker_name_pattern = re.compile(r\"\\w+\\s[\\($]\"\n",
    "                                     \"|\\w+;\")\n",
    "    candidates = [p[:-1].upper().rstrip() for p in re.findall(speaker_name_pattern, candidates_desc) ]\n",
    "    moderators = [p[:-1].upper().rstrip() for p in re.findall(speaker_name_pattern, moderators_desc) ]\n",
    "    return candidates, moderators, remove_html(candidates_desc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidate_speech(debate_text):\n",
    "    \"\"\"\n",
    "    Select only text of speech by candidates and ignore moderators. Cleanup, annotate and arrange.\n",
    "    \"\"\"\n",
    "    candidate_list, mod_list, candidates_desc = get_speaker_list(debate_text)\n",
    "    debate_text_split = debate_text.split(\"<b>\")[1:]\n",
    "    candidate_speech = []\n",
    "    for line in debate_text_split:\n",
    "        speaker = line.split(\":\")[0]\n",
    "        speech = line.split(\":\")[1:]\n",
    "        if len(speech)>1:\n",
    "            speech = \"\".join([x for x in speech])\n",
    "        elif len(speech) >0:\n",
    "            speech = speech[0]   \n",
    "        else:\n",
    "            speech = \"\"\n",
    "        for candidate in candidate_list:\n",
    "            if speaker==candidate:\n",
    "                candidate_speech.append([speaker, remove_html(speech)])\n",
    "    return candidate_speech, remove_html(candidates_desc)\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['CLINTON', 'SANDERS'],\n",
       " ['BLITZER'],\n",
       " 'Former Secretary of State Hillary Clinton;Senator Bernie Sanders (VT); ')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_speaker_list(debates[str(5)][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(1, 149):\n",
    "    try:\n",
    "        candidates, moderators, candidates_desc = get_speaker_list(debates[str(i)][\"text\"])\n",
    "        print(i, candidates, moderators, debates[str(i)][\"url\"])\n",
    "    except:\n",
    "        print(i, [], debates[str(i)][\"url\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select debates where this speaker identification scheme works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll devise a different scheme for the other debates. Some of them def require manual annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "part1 = np.concatenate([np.arange(1,34), np.arange(38,58), \n",
    "                   np.arange(62,75), np.arange(76,79), \n",
    "                   np.arange(81,87), np.arange(88,94), [95], \n",
    "                   np.arange(115,125)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "        27,  28,  29,  30,  31,  32,  33,  38,  39,  40,  41,  42,  43,\n",
       "        44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
       "        57,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,\n",
       "        74,  76,  77,  78,  81,  82,  83,  84,  85,  86,  88,  89,  90,\n",
       "        91,  92,  93,  95, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
       "       124])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(part1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "debates_clean = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in part1:\n",
    "    debates_clean[str(i)] = {}\n",
    "    candidates_speech, candidates_desc = get_candidate_speech(debates[str(i)][\"text\"])\n",
    "    debates_clean[str(i)][\"candidates_desc\"] = candidates_desc\n",
    "    debates_clean[str(i)][\"candidates_speech\"] = candidates_speech\n",
    "    debates_clean[str(i)][\"date\"] = debates[str(i)][\"date\"]\n",
    "    debates_clean[str(i)][\"desc\"] = debates[str(i)][\"desc\"]\n",
    "    debates_clean[str(i)][\"url\"] = debates[str(i)][\"url\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"debates_clean_part1.json\", \"w\") as f:\n",
    "    json.dump(debates_clean, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentences(long_text, len_thresh=20):\n",
    "    long_text = re.sub(r\"\\.\\.\\.\", \" \", long_text) # remove \"...\"\n",
    "    text_splits = long_text.split(\".\")\n",
    "    text_splits = [x for x in text_splits if len(x)>len_thresh]\n",
    "    return text_splits\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_list = []\n",
    "for i in part1:\n",
    "    debate_i = debates_clean[str(i)][\"candidates_speech\"]\n",
    "    date_i = debates_clean[str(i)][\"date\"]\n",
    "    for line in debate_i:\n",
    "        statement_split = split_sentences(line[1])\n",
    "        for x in statement_split:\n",
    "            speech_list.append([line[0], int(date_i[-4:]), x.lstrip(' ').rstrip()])\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_list_df = pd.DataFrame(speech_list, columns = [\"Speaker\", \"Year\", \"Sentence\"])\n",
    "speech_list_df.to_csv(\"debate_sentences_part1.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
